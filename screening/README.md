# Screening Title & Abstract

| **Cite Key** | **Method** | **add info** |
| --- | --- | --- |
| Battula2025Latentneuronet |  fMRI, Latent Diffusion Model (LDM), Bootstrapping Language-Image Pre-training (BLIP) | add denoising method |
| Chen2025Mindgpt | fMRI,guided cross attention, explanable, HVC, LVC(high low visual cortex) | https://github.com/JxuanC/MindGPT |
| Choi2025International | EEG, limit on spatial, spectral, and temporal (SST) | perbandingan dengan THINGS-EEG |
| Deng2025Image | fMRI, Visual Transformer, reconstruct artificial sapes| perceived content based on the hierarchical neural representations |
| ~~Dong2025High~~ | microelectrode array, pigeon, RGB reconstruct | pada merpati bukan manusia, tapi bisa dipakai algoritmanya |
| Gao2025Mindd | fMRI, stimulus gambar 3D | menyediakan fMRI-3D dataset  https://huggingface.co/datasets/Fudan-fMRI/fMRI-Shape , https://huggingface.co/datasets/Fudan-fMRI/fMRI-Objaverse , https://jianxgao.github.io/MinD-3D  |
| Huo2025Neuropictor | fMRI, Diffusion Model, multi subject| Multi Subjek, https://jingyanghuo.github.io/neuropictor/ |
| Kamitani2025Visual | discuss dataset and metric eval | seperti paper review |
| Li2025Deep | first review on EEG-based visual classification and reconstruction | paper review EEG |
| Lotey2025Eegbased | EEG, Parameter-efficient fine-tuning (PEFT), speech and motor imagery | rehab stroke |
| Ma2025Brainclip | fMRI, BrainCLIP, CLIP, Contrastife learning | BrainCLIP surpasses BraVL, multi modal, zero-shot |
| Mai2025Brainconditional | taxonomy according to AIGC-brain methodologies | SLR |
| Nigam2025Eegdepth | EEG, contrastive learning framework, GNN  | GNN |
| Olza2025Domain |  fMRI, imagined stimuli, Domain Adaptation (DA) |  visual cortex and the frontoparietal cortex |
| Peng2025Decoding | recorded retinal spike data,natural video stimuli,Wavelet-Informed Spike Augmentation (WISA) model | that can be directly fed into deep reconstruction networks |
| PossoMurillo2025Ieee | decode the meaning of words or sentences, functional near-infrared spectroscopy (fNIRS) | language decoding, https://github.com/sposso/Semantic-Reconstruction-using-fNIRS-signal |
| Qu2025Uncovering | fMRI, masked autoencoder (MAE) model | robust cross-subject fMRI signal reconstruction |
| ~~RodrguezDeliz2025Neural~~ | V1, V2, V4, and PIT to radial frequency patternsâ€”a type of global form stimulus | pada Macaques bukan manusia |
| Shakeripour2025Object | fMRI, Natural Scenes categorize, pre-trained inceptionv3, transformer network  | multi subject with visual space and fMRI space, new subjects |
| Sharon2025Harnessing | EEG, Imagined Speech Recognition, multi-phasal data | human communication involves multiple phases like audition, imagination, articulation, and production |
| Shirakawa2025Spurious | (Natural Scenes Dataset, NSD), UMAP visualization, DM | text-guided reconstructions, rekonstruksi citra yang mengada-ada |
| Shoura2025Revealing | EEG, face space compression, perbedaan sinyal antar ras, behavioral measures, neural decoding, and image reconstruction based | other-race effect (ORE), perbedaan sinyal otak orang asia dan barat |
| Tian2025Brainguard | fMRI, BRAINGUARD framework for image recons multi subject | cross-subject, multisubject  |
| Veronese2025Optimized | optimase non linear mapping, VAE, LDM, CLIP, natural image | optimized neural decoding architecture |
| Xiong2025Interpretable | EEG, ISTANet, rapid serial visual presentation (RSVP) | Cross-modal aligned network |
| Xu2025Brainvision | THINGS-EEG, DEAP emotional response dataset  | bridges visual recognition and emotional EEG datasets to enable comprehensive visual content generation through cross-domain learning |
| Yu2025Robust | retinal neural spike, two movies with different levels of scene, decoding dynamical visual scenes using retinal spikes | robust relationship between stimuli and neural responses |
||||
||||
||||
||||
||||
||||
||||
||||
||||
||||
||||
||||
||||
||||
||||
||||
||||
||||
||||
||||
||||
||||
||||
||||
||||
||||
||||
||||
||||
||||
||||
||||
||||
||||
||||
||||
||||
||||
||||
||||
||||
||||
||||
||||
||||
||||
||||
||||
||||
||||
||||
||||
||||
||||
||||
||||
||||
||||
||||
||||
||||
||||
||||
||||
||||
||||
||||
||||
||||
||||
||||